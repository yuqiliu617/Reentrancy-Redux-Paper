\section{Related Work}

The significant fund loss from The DAO attack in 2016 first brought reentrancy vulnerabilities into the spotlight~\cite{the-dao-analysis}. Researchers have since proposed various detection methods, including static analysis, dynamic analysis, and, more recently, attacker-focused approaches~\cite{survey:detection}.

\textbf{Static Analysis:} These tools detect vulnerabilities pre-deployment. Early tools like Oyente~\cite{oyente} and Manticore~\cite{manticore} used symbolic execution. Slither~\cite{slither} introduced an intermediate representation (IR) for Solidity, enabling broader detection. Others like Zeus~\cite{zeus}, Securify~\cite{securify}, and Vandal~\cite{vandal} applied formal verification with predefined policies. While effective in specific domains, most static tools struggle with cross-contract interactions (common in DeFi, \eg via proxy contracts~\cite{erc1967}) and suffer from high false positive/negative rates~\cite{survey:static-analysis}.

\textbf{Dynamic Analysis:} These tools monitor execution to detect vulnerabilities at runtime. For instance, Sereum~\cite{sereum} uses taint analysis integrated into Ethereum to flag suspicious behavior. ReGuard~\cite{reguard} and ContractFuzzer~\cite{contractfuzzer} use fuzzing to generate inputs and examine traces. While Sereum handles cross-contract interactions, it only supports post-deployment detection. Fuzzers, though effective, face scalability challenges with complex input formats~\cite{fuzzing-review}.

\textbf{Recent Advancements:} Recognizing existing tool limitations, recent research explored novel approaches. Roychoudhury \etal~\cite{attack-contract-detection} analyzed attacker contract patterns. However, many recent exploits deploy attack contracts mid-transaction, preventing preemptive detection (see Section~\ref{quantitative:attack-timeline}). Zhang \etal~\cite{smartreco} and Grundy \etal~\cite{clairvoyance} proposed tools for analyzing cross-contract interactions. Despite advances, comprehensive and proactive reentrancy detection remains unsolved.

Additionally, recent benchmarks on real-world and synthetic datasets expose significant shortcomings in existing tools. Ghaleb \etal~\cite{survey:static-analysis} assessed six widely-used static analyzers on synthetic contracts, revealing substantial false positive/negative rates. Similarly, Zheng \etal~\cite{turn-the-rudder} evaluated five major tools on real Ethereum transactions, finding high FP rates (up to 99.8\%) and failures to detect non-classic reentrancy patterns (\ie deviating from \lstinline{call.value}). These results align with our observations, underscoring the need for more robust reentrancy detection mechanisms.